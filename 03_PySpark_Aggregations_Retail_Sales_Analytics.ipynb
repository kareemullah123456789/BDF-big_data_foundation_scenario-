{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891a9d1c",
   "metadata": {},
   "source": [
    "# Module 3: PySpark Aggregations - Retail Sales Analytics\n",
    "**Scenario:** Working for a Service Company (e.g., TCS/Infosys) for a Retail Client (e.g., Walmart, Target, Tesco).\n",
    "\n",
    "**Objective:** Compute Key Performance Indicators (KPIs) like Total Revenue, Top Selling Products, and Store Performance.\n",
    "\n",
    "**Thinking Like a Data Engineer:**\n",
    "In retail, raw transaction data (POS data) is massive (billions of rows).\n",
    "*   **Managers don't want raw data.** They want *Aggregates* (Sums, Averages, Counts).\n",
    "*   **Your Job:** Take the 100GB of raw sales data -> Group By Store/Product -> Calculate Metrics -> Save Small Report.\n",
    "\n",
    "---\n",
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe311f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup PySpark\n",
    "try:\n",
    "    import pyspark\n",
    "    print(\"PySpark is already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing PySpark...\")\n",
    "    !pip install pyspark findspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Retail_Sales_Analytics\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9253f",
   "metadata": {},
   "source": [
    "## 2. Load Sales Data (Simulate POS System)\n",
    "We will create a DataFrame representing daily sales across different stores.\n",
    "*   `store_id`: Which physical store?\n",
    "*   `product_id`: What item?\n",
    "*   `category`: Electronics, Grocery, etc.\n",
    "*   `quantity`: How many sold?\n",
    "*   `unit_price`: Cost per item.\n",
    "*   `cost_price`: How much the store paid (needed for profit calculation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcf924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate Mock Sales Data ---\n",
    "sales_data = [\n",
    "    (\"Store_NYC_1\", \"TV_55_Inch\", \"Electronics\", 5, 500.0, 300.0),\n",
    "    (\"Store_NYC_1\", \"Laptop_Pro\", \"Electronics\", 2, 1200.0, 900.0),\n",
    "    (\"Store_NYC_1\", \"Milk_1Gal\", \"Grocery\", 100, 4.5, 3.0),\n",
    "    (\"Store_LA_1\", \"TV_55_Inch\", \"Electronics\", 10, 500.0, 300.0),\n",
    "    (\"Store_LA_1\", \"Laptop_Pro\", \"Electronics\", 5, 1200.0, 900.0),\n",
    "    (\"Store_LA_1\", \"Milk_1Gal\", \"Grocery\", 150, 4.5, 3.0),\n",
    "    (\"Store_CHI_1\", \"TV_55_Inch\", \"Electronics\", 1, 500.0, 300.0), # Low sales\n",
    "    (\"Store_CHI_1\", \"Milk_1Gal\", \"Grocery\", 20, 6.0, 3.0)  # Higher price\n",
    "]\n",
    "\n",
    "schema = [\"store_id\", \"product_name\", \"category\", \"quantity\", \"unit_price\", \"cost_price\"]\n",
    "df_sales = spark.createDataFrame(sales_data, schema=schema)\n",
    "\n",
    "print(\"--- Raw Daily Sales Data ---\")\n",
    "df_sales.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474df4a",
   "metadata": {},
   "source": [
    "## 3. Basic Calculations: Revenue & Profit\n",
    "Raw data often gives you Quantity and Unit Price.\n",
    "We need to calculate:\n",
    "1.  **Total Revenue per Row** = `quantity` * `unit_price`\n",
    "2.  **Total Cost per Row** = `quantity` * `cost_price`\n",
    "3.  **Profit per Row** = Revenue - Cost\n",
    "\n",
    "**Pyspark Tool:** `withColumn(\"new_col_name\", expression)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate Total Revenue\n",
    "df_calculated = df_sales.withColumn(\"total_revenue\", col(\"quantity\") * col(\"unit_price\"))\n",
    "\n",
    "# 2. Calculate Total Cost\n",
    "df_calculated = df_calculated.withColumn(\"total_cost\", col(\"quantity\") * col(\"cost_price\"))\n",
    "\n",
    "# 3. Calculate Profit\n",
    "df_calculated = df_calculated.withColumn(\"profit\", col(\"total_revenue\") - col(\"total_cost\"))\n",
    "\n",
    "print(\"--- Sales with Revenue & Profit ---\")\n",
    "df_calculated.show()\n",
    "# Can you see which product makes the most money? Not yet. We need to Group By."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaeecbc",
   "metadata": {},
   "source": [
    "## 4. Aggregation: Where the Business Value Is\n",
    "CEOs don't look at single transactions. They ask:\n",
    "1.  **Which Store made the most money?** (Group By `store_id`)\n",
    "2.  **Which Category has the highest sales?** (Group By `category`)\n",
    "\n",
    "**PySpark Tool:** `groupBy(\"col\").agg(sum(\"col\"), avg(\"col\"))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e226e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Total Revenue Per Store\n",
    "df_store_revenue = df_calculated.groupBy(\"store_id\") \\\n",
    "    .agg(\n",
    "        sum(\"total_revenue\").alias(\"revenue\"),\n",
    "        sum(\"profit\").alias(\"net_profit\")\n",
    "    ) \\\n",
    "    .orderBy(\"revenue\", ascending=False) # Rank them highest to lowest\n",
    "\n",
    "print(\"--- Top Performing Stores ---\")\n",
    "df_store_revenue.show()\n",
    "\n",
    "# 2. Category Performance\n",
    "df_category_performance = df_calculated.groupBy(\"category\") \\\n",
    "    .agg(\n",
    "        sum(\"quantity\").alias(\"units_sold\"),\n",
    "        avg(\"unit_price\").alias(\"avg_price\")\n",
    "    )\n",
    "\n",
    "print(\"--- Category Insights ---\")\n",
    "df_category_performance.show()\n",
    "# Notice: Groceries sell MANY units (270) but at low price ($4.6). Electronics sell few (23) but expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6893e",
   "metadata": {},
   "source": [
    "## 5. Identifying \"Loss Leaders\" (Or Low Margin Items)\n",
    "Sometimes high sales doesn't mean high profit.\n",
    "Let's calculate the **Margin Percentage** `(Profit / Revenue) * 100`.\n",
    "\n",
    "*   If Margin < 10%, we might be discounting too much.\n",
    "*   This is called \"Margin Analysis\" - very common in retail interviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbcf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Group By Product and Sum revenue/profit\n",
    "df_product_margins = df_calculated.groupBy(\"product_name\") \\\n",
    "    .agg(\n",
    "        sum(\"total_revenue\").alias(\"product_revenue\"),\n",
    "        sum(\"profit\").alias(\"product_profit\")\n",
    "    )\n",
    "\n",
    "# 2. Calculate Margin %\n",
    "df_product_margins = df_product_margins.withColumn(\n",
    "    \"margin_percentage\",\n",
    "    round((col(\"product_profit\") / col(\"product_revenue\")) * 100, 2)\n",
    ")\n",
    "\n",
    "print(\"--- Product Profitability ---\")\n",
    "df_product_margins.orderBy(\"margin_percentage\").show()\n",
    "\n",
    "# 3. Filter Low Margin Products (< 30%)\n",
    "df_low_margin = df_product_margins.filter(col(\"margin_percentage\") < 30)\n",
    "\n",
    "print(\"--- WARNING: Low Margin Products (Check Pricing Strategy) ---\")\n",
    "df_low_margin.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed5e8d",
   "metadata": {},
   "source": [
    "## 6. Save The Report\n",
    "Instead of Parquet, business managers often want **CSV** reports they can open in Excel.\n",
    "We will save the **Store Revenue** report as a CSV.\n",
    "\n",
    "*   `header=true`: So they see column names.\n",
    "*   `coalesce(1)`: Merges all partitions into 1 file (Useful for small reports < 1GB, so you don't get 100 tiny files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105e659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"store_sales_report_csv\"\n",
    "\n",
    "# Coalesce to 1 single CSV file (For easy emailing/Excel use)\n",
    "df_store_revenue.coalesce(1).write.option(\"header\", \"true\").mode(\"overwrite\").csv(output_path)\n",
    "\n",
    "print(f\"Sales Report Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
